{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TImjwX9voJPj"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsfgIpWJ9BkQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "import pathlib\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPHkYJIHoQVj"
      },
      "source": [
        "Connecting google colab to google drive where the dataset is.\n",
        "\n",
        "This is the link for dataset https://www.kaggle.com/ashishjangra27/face-mask-12k-images-dataset\n",
        "\n",
        "We have used only training images from this.\n",
        "\n",
        "There are 10k images of which 5k are with mask and 5k without mask."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oFcLeGC93C0",
        "outputId": "96e0911c-214c-43e5-80d2-a0297bcfdc6b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhSCoYY1-MTF"
      },
      "source": [
        "data_dir=\"/content/drive/MyDrive/FaceMaskDataset\"\n",
        "data_dir=pathlib.Path(data_dir)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzs6owNcpI3-"
      },
      "source": [
        "Declaring batch size.\n",
        "\n",
        "Since images used are of different sizes but for training model we need images of same size therefore we have to resize all the images of dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcVOe3Pc-iO3"
      },
      "source": [
        "batch_size=8\n",
        "img_height=64\n",
        "img_width=64"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VlhvOmTpqU9"
      },
      "source": [
        "Splitting dataset into 2 parts for training the model and testing it.\n",
        "\n",
        "We are dividing dataset in 80:20 ratio.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZvv98GzszPT"
      },
      "source": [
        "Seed is used for shuffling data.\n",
        "\n",
        "We use seed value while creating training and test dataset.\n",
        "\n",
        "Giving a seed value makes sure every time same we get same train and test dataset for changing hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20mjvQir-sD8",
        "outputId": "1d6518fb-c399-4884-f279-62f9658f5009"
      },
      "source": [
        "ds_train=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,validation_split=0.2,subset='validation',seed=80,\n",
        "    image_size=(img_height,img_width), batch_size=batch_size\n",
        ")\n",
        "\n",
        "\n",
        "ds_val=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,validation_split=0.2,subset='validation',seed=80,\n",
        "    image_size=(img_height,img_width), batch_size=batch_size\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 files belonging to 2 classes.\n",
            "Using 2000 files for validation.\n",
            "Found 10000 files belonging to 2 classes.\n",
            "Using 2000 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYOlMjb-_V47",
        "outputId": "5730569c-da00-4406-e201-c33c2d2cbb93"
      },
      "source": [
        "class_names=ds_train.class_names\n",
        "print(class_names)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['WithMask', 'WithoutMask']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLtFglRns3g-"
      },
      "source": [
        "For memory optimization and faster execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1Rf6IVkAhdc"
      },
      "source": [
        "AUTOTUNE=tf.data.experimental.AUTOTUNE\n",
        "ds_train=ds_train.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "ds_val=ds_val.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efdq3pbUVElF"
      },
      "source": [
        "n_class=2"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFufeE8BtPcg"
      },
      "source": [
        "### Building CNN Network\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWKbQbfHtaHw"
      },
      "source": [
        "First we rescaled all the values to 0-1.\n",
        "\n",
        "Rescaling increses the accuracy of model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X98oOKjttBX"
      },
      "source": [
        "MODEL\n",
        "\n",
        "input--->Conv2D+ReLU--->MaxPool--->Conv2D+ReLU--->MaxPool--->Conv2D+ReLU--->MaxPool--->Dropout--->Flatten--->Fully Connected--->Fully Connected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VXMqi16wDVx"
      },
      "source": [
        "We used dropout layer to avoid overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42UtZxXZVopD",
        "outputId": "8083b380-f470-4e23-ba03-ebb5222f9e84"
      },
      "source": [
        "model =Sequential([\n",
        "\n",
        "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "\n",
        "  layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
        "\n",
        "  layers.MaxPooling2D(),\n",
        "\n",
        "  layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
        "\n",
        "  layers.MaxPooling2D(),\n",
        "\n",
        "  layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "\n",
        "  layers.MaxPooling2D(),\n",
        "\n",
        "  layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "\n",
        "  layers.MaxPooling2D(),\n",
        "\n",
        "  layers.Dropout(0.2),\n",
        "\n",
        "  layers.Flatten(),\n",
        "\n",
        "  layers.Dense(units=64, activation='relu'),\n",
        "\n",
        "  layers.Dense(n_class)\n",
        "\n",
        "  ])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rescaling_3 (Rescaling)      (None, 64, 64, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 62, 62, 16)        448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 31, 31, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 29, 29, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 77,090\n",
            "Trainable params: 77,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdQaRojZvRo2"
      },
      "source": [
        "Compling model using adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kEzxwUlW8Bv",
        "outputId": "f8725a9c-e320-45a2-960a-623b83922dfc"
      },
      "source": [
        "model.compile(optimizer =\"adam\", loss =tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics =['accuracy'])\n",
        "\n",
        "mymodel=model.fit(ds_train, validation_data=ds_val, epochs=9)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "250/250 [==============================] - 13s 48ms/step - loss: 0.0242 - accuracy: 0.9920 - val_loss: 0.0175 - val_accuracy: 0.9925\n",
            "Epoch 2/9\n",
            "250/250 [==============================] - 12s 46ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0050 - val_accuracy: 0.9980\n",
            "Epoch 3/9\n",
            "250/250 [==============================] - 11s 46ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.0148 - val_accuracy: 0.9935\n",
            "Epoch 4/9\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.0283 - accuracy: 0.9895 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 5/9\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.0129 - accuracy: 0.9945 - val_loss: 0.0077 - val_accuracy: 0.9980\n",
            "Epoch 6/9\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.0188 - accuracy: 0.9930 - val_loss: 0.0071 - val_accuracy: 0.9965\n",
            "Epoch 7/9\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 9.2556e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/9\n",
            "250/250 [==============================] - 12s 46ms/step - loss: 0.0142 - accuracy: 0.9930 - val_loss: 0.0037 - val_accuracy: 0.9990\n",
            "Epoch 9/9\n",
            "250/250 [==============================] - 12s 47ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0026 - val_accuracy: 0.9995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZVdc899v2Ip"
      },
      "source": [
        "Achieved 99.95% accuracy on new dataset"
      ]
    }
  ]
}